{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYVTmyUPuqM9jXxTu1EdNp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sankytanky100/software-engineering/blob/main/Text_Classification_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Project Overview*\n",
        "\n",
        "**Text Classification Pipeline with OOP in Python**\n",
        "\n",
        "Objective:\n",
        "Data Loading and Preprocessing: Clean and preprocess text data.\n",
        "\n",
        "Feature Extraction: Convert text data into numerical features using TF-IDF.\n",
        "\n",
        "Model Building: Train a classification model (e.g., Logistic Regression).\n",
        "\n",
        "Model Evaluation: Evaluate the model's performance.\n",
        "\n",
        "Pipeline Management: Use OOP to create reusable and modular code components.\n",
        "Why This Project?\n"
      ],
      "metadata": {
        "id": "-tScMSnhxjfr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaTbAZLhxgSL",
        "outputId": "055fa29e-1171-4343-92ce-680036880446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataHandler:\n",
        "    \"\"\"\n",
        "    A class to handle data loading and initial preprocessing.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_source):\n",
        "        self.data_source = data_source\n",
        "        self.data = None\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Loads data from the data source.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclass must implement abstract method\")\n"
      ],
      "metadata": {
        "id": "qtcWpZUXyEUx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CSVDataHandler:\n",
        "    def __init__(self, data_source):\n",
        "        self.data_source = data_source\n",
        "        self.data = None\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Loads data from a CSV file.\n",
        "        \"\"\"\n",
        "        # Change from pd.read_csv to pd.read_table or pd.read_csv(..., sep='\\t')\n",
        "        # self.data = pd.read_csv(self.data_source)  # Original line\n",
        "        self.data = pd.read_table(self.data_source, header=None, names=['label', 'text'])  # Changed line to pd.read_table\n",
        "        # or\n",
        "        # self.data = pd.read_csv(self.data_source, sep='\\t')  # Alternative using pd.read_csv with sep='\\t'\n",
        "        print(\"Data loaded successfully from {}\".format(self.data_source))\n",
        "        return self.data\n"
      ],
      "metadata": {
        "id": "hq3vjdzbyGAQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocessor:\n",
        "    \"\"\"\n",
        "    A class for text preprocessing.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"\n",
        "        Cleans the input text.\n",
        "        \"\"\"\n",
        "        # Remove URLs\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        # Remove HTML tags\n",
        "        text = re.sub(r'<.*?>', '', text)\n",
        "        # Remove punctuation\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "        # Remove numbers\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        # Remove extra whitespace\n",
        "        text = text.strip()\n",
        "        return text.lower()\n",
        "\n",
        "    def preprocess(self, texts):\n",
        "        \"\"\"\n",
        "        Applies cleaning to a list of texts.\n",
        "        \"\"\"\n",
        "        return [self.clean_text(text) for text in texts]\n"
      ],
      "metadata": {
        "id": "LnQMYVJPyIJH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor:\n",
        "    \"\"\"\n",
        "    A class for feature extraction from text data.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "\n",
        "    def fit_transform(self, texts):\n",
        "        \"\"\"\n",
        "        Fits the vectorizer to the texts and transforms them.\n",
        "        \"\"\"\n",
        "        return self.vectorizer.fit_transform(texts)\n",
        "\n",
        "    def transform(self, texts):\n",
        "        \"\"\"\n",
        "        Transforms texts using the fitted vectorizer.\n",
        "        \"\"\"\n",
        "        return self.vectorizer.transform(texts)\n"
      ],
      "metadata": {
        "id": "RRXrXikoyJ6J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    \"\"\"\n",
        "    A class for training the classification model.\n",
        "    \"\"\"\n",
        "    def __init__(self, model=None):\n",
        "        if model is None:\n",
        "            self.model = LogisticRegression()\n",
        "        else:\n",
        "            self.model = model\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Trains the model.\n",
        "        \"\"\"\n",
        "        self.model.fit(X_train, y_train)\n",
        "        print(\"Model trained successfully.\")\n",
        "        return self.model\n"
      ],
      "metadata": {
        "id": "ZwseULTzyLkt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelEvaluator:\n",
        "    \"\"\"\n",
        "    A class for evaluating the classification model.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def evaluate(self, model, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluates the model on the test data.\n",
        "        \"\"\"\n",
        "        y_pred = model.predict(X_test)\n",
        "        print(\"Classification Report:\\n\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print(\"Confusion Matrix:\\n\")\n",
        "        print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "0V9MTCEeyM-l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationPipeline:\n",
        "    \"\"\"\n",
        "    A class that encapsulates the entire text classification pipeline.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_handler, preprocessor, feature_extractor, model_trainer, evaluator):\n",
        "        self.data_handler = data_handler\n",
        "        self.preprocessor = preprocessor\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.model_trainer = model_trainer\n",
        "        self.evaluator = evaluator\n",
        "\n",
        "    def run(self):\n",
        "        # Load data\n",
        "        data = self.data_handler.load_data()\n",
        "\n",
        "        # Assume the data has 'text' and 'label' columns\n",
        "        texts = data['text']\n",
        "        labels = data['label']\n",
        "\n",
        "        # Preprocess text\n",
        "        texts = self.preprocessor.preprocess(texts)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Feature extraction\n",
        "        X_train_feats = self.feature_extractor.fit_transform(X_train)\n",
        "        X_test_feats = self.feature_extractor.transform(X_test)\n",
        "\n",
        "        # Train model\n",
        "        model = self.model_trainer.train(X_train_feats, y_train)\n",
        "\n",
        "        # Evaluate model\n",
        "        self.evaluator.evaluate(model, X_test_feats, y_test)\n"
      ],
      "metadata": {
        "id": "32bbh-QJyOKy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31KHkivsyP9l",
        "outputId": "e28e6f33-ea8b-47ec-9f2d-0cd708ac8ac6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-19 00:22:22--  https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 477907 (467K) [text/plain]\n",
            "Saving to: ‘sms.tsv.1’\n",
            "\n",
            "\rsms.tsv.1             0%[                    ]       0  --.-KB/s               \rsms.tsv.1           100%[===================>] 466.71K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-11-19 00:22:22 (16.0 MB/s) - ‘sms.tsv.1’ saved [477907/477907]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data_source = 'sms.tsv'\n",
        "data = pd.read_table(data_source, header=None, names=['label', 'text'])\n",
        "\n",
        "# Map labels to binary values\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n"
      ],
      "metadata": {
        "id": "5q2lNWNQySuK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate components\n",
        "data_handler = CSVDataHandler(data_source)\n",
        "preprocessor = TextPreprocessor()\n",
        "feature_extractor = FeatureExtractor()\n",
        "model_trainer = ModelTrainer()\n",
        "evaluator = ModelEvaluator()\n"
      ],
      "metadata": {
        "id": "F_09gKU9yT-r"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the pipeline\n",
        "pipeline = TextClassificationPipeline(\n",
        "    data_handler=data_handler,\n",
        "    preprocessor=preprocessor,\n",
        "    feature_extractor=feature_extractor,\n",
        "    model_trainer=model_trainer,\n",
        "    evaluator=evaluator\n",
        ")\n",
        "\n",
        "# Run the pipeline\n",
        "pipeline.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfqlfQexyVU-",
        "outputId": "619568b9-c019-4248-86a1-5943994af11a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully from sms.tsv\n",
            "Model trained successfully.\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98       966\n",
            "        spam       0.99      0.79      0.88       149\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.89      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[965   1]\n",
            " [ 32 117]]\n"
          ]
        }
      ]
    }
  ]
}